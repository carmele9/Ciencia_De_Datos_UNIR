{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Actividad 4: Clasificación multiclase con Scikit-learn y TensorFlow sobre dataset diamonds\n",
    "# Carmen De Los Ángeles Camacho Tejada - 16/02/2025\n",
    "# Ciencia De Datos - UNIR\n",
    "# Profesor Alan Sastre - Módulo 2\n",
    "\n",
    "# Importamos las librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargamos el dataset 'tips' desde seaborn\n",
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Mostramos las primeras filas del dataset\n",
    "data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*_ANÁLISIS DE ESTADÍSTICAS DESCRIPTIVAS_*",
   "id": "fd8b4409cbf0f647"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Información general del dataset\n",
    "data.info()"
   ],
   "id": "68ce475e92be61da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estadísticas de las variables numéricas del dataset\n",
    "data.describe()"
   ],
   "id": "d21b6ad390b9f81a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Descripción de las variables categóricas del dataset\n",
    "data.describe(include=['object'])"
   ],
   "id": "b13ebd2a5bc5f5b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Verificación de valores nulos\n",
    "data.isnull().sum()"
   ],
   "id": "57369792a2eaa5e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribución de la variable a predecir: 'cut'\n",
    "data['cut'].value_counts()"
   ],
   "id": "32d4414ebda533ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribución de las otras variables categóricas\n",
    "columnas_category = ['color', 'clarity']\n",
    "for col in columnas_category:\n",
    "    print(data[col].value_counts())"
   ],
   "id": "4da848fbedd7a6c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Para mejor entendimiento de la columna <cut>, se realiza un gráfico de barras\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.countplot(x='cut', data=data, color=\"chocolate\", edgecolor=\"black\")\n",
    "plt.title('Distribución de la variable Cut', fontsize=16, fontweight=\"bold\", color=\"peru\")\n",
    "plt.show()\n"
   ],
   "id": "52bea6d828db0c59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_LIMPIEZA DE DATOS_*\n",
    "\n",
    "1. Revisar valores nulos.\n",
    "2. Detectar y tratar valores atípicos (outliers).\n",
    "3. Revisar y convertir tipos de datos si es necesario.\n",
    "4. Eliminar columnas irrelevantes.\n",
    "\n",
    "Dado que en la anterior actividad, no llegué a tratar valores nulos ni duplicados, he decidido en esta, crear algunos y corregirlos posteriormente para practicar este paso (en la vida real, las bases de datos están llenas de estos)."
   ],
   "id": "9134ebadd4ae21e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# VALORES NULOS\n",
    "# Introducir valores nulos en algunas filas:\n",
    "# Cada 50, se añadirá un valor nulo en la columna 'carat'\n",
    "# Cada 75, se añadirá un valor nulo en la columna a predecir 'cut'\n",
    "# Cada 100, se añadirá un valor nulo en la columna 'price'\n",
    "\n",
    "data.loc[::50, 'carat'] = np.nan\n",
    "data.loc[::75, 'cut'] = np.nan\n",
    "data.loc[::100, 'price'] = np.nan"
   ],
   "id": "e440a0ba9d084ce9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Revisar valores nulos\n",
    "# Como se añadieron antes valores nulos, ahora SI deben aparecer aquí, diferenciándose de cuando se hizo más arriba\n",
    "data.isnull().sum()"
   ],
   "id": "ab9baea57b01ab39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rellenar valores nulos con distintos procedimientos vistos en clase:\n",
    "# 'carat' -> la media\n",
    "# 'cut' -> la moda\n",
    "# 'price' -> la mediana\n",
    "\n",
    "data = data.assign(\n",
    "    carat=data['carat'].fillna(data['carat'].mean()),\n",
    "    cut=data['cut'].fillna(data['cut'].mode()[0]),\n",
    "    price=data['price'].fillna(data['price'].median())\n",
    ")"
   ],
   "id": "c68dd852ca691e0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Revisamos de nuevo los valores nulos\n",
    "data.isnull().sum()"
   ],
   "id": "8a596a607fd1c21f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# OUTLIERS\n",
    "# Detectar y tratar valores atípicos:\n",
    "# Se puede detectar estos usando diagramas de caja con las columnas numéricas\n",
    "columnas_numerical = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.set_style(\"white\")\n",
    "sns.boxplot(data=data[columnas_numerical], palette=\"viridis\")\n",
    "plt.title(\"Detección de valores atípicos\", fontsize=16, fontweight='bold', color=\"lightblue\")\n",
    "plt.show()"
   ],
   "id": "8cbbba433f5f7196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Para tratar los outliers, se usará el valor inter cuartil, IQR\n",
    "def detectar_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] < limite_inferior) | (df[column] > limite_superior)]"
   ],
   "id": "d98792ee1d7466e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for columna in columnas_numerical:\n",
    "    outliers = detectar_outliers(data, columna)\n",
    "    print(f\"Outliers detectados en {columna}: {len(outliers)}\")\n",
    "    # Eliminar los outliers del dataset\n",
    "    data = data[~data.index.isin(outliers.index)]\n"
   ],
   "id": "1692be4e241d100e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualizar con un boxplot para confirmar que no hay valores atípicos\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.set_style(\"white\")\n",
    "sns.boxplot(data=data[columnas_numerical], palette=\"viridis\")\n",
    "plt.title('Boxplot de la columna depth después de eliminar outliers', fontsize=16, fontweight='bold', color=\"indianred\")\n",
    "plt.show()\n",
    "\n",
    "for columna in columnas_numerical:\n",
    "   outliers = detectar_outliers(data, columna)\n",
    "   print(f\"Outliers detectados en {columna}: {len(outliers)}\")"
   ],
   "id": "7e23e40bfdaaae7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Vemos que, aunque se han reducido en gran medida los valores atípicos, aún no se han eliminado por completo. Esto puede ser normal dependiendo del contexto y el tipo de datos. Por ejemplo, los outliers pueden representar diamantes muy caros o muy grandes. Por ahora, he decidido no eliminarlos porque podría distorsionar el análisis.\n",
    "\n",
    "Más adelante, cuando se realize la preparación de datos, se probará el método de RobustScaler. Esta es una técnica de escalado que ayuda a reducir el impacto de los outliers en los datos. A diferencia de otros escaladores como StandardScaler (que usa la media y la desviación estándar), RobustScaler usa la mediana y el rango intercuartílico (IQR), lo que lo hace menos sensible a valores extremos. Como en la anterior actividad utilizé el StandardScaler, en esta probaré esta técnica para ver su funcionamiento y entender su diferencia."
   ],
   "id": "7598bc14d90c3a7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TIPOS DE DATOS:\n",
    "# Revisar y convertir tipos de datos si es necesario\n",
    "data.dtypes"
   ],
   "id": "457002e3e35a2341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Voy a corregir las columnas 'cut', 'color', 'clarity' cambiándolas a tipo categoría\n",
    "data = data.assign(\n",
    "    cut=data['cut'].astype('category'),\n",
    "    color=data['color'].astype('category'),\n",
    "    clarity=data['clarity'].astype('category')\n",
    ")\n",
    "data.dtypes # Comprobación del arreglo"
   ],
   "id": "c869cc23069d604e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# COLUMNAS IRRELEVANTES:\n",
    "# Eliminar columnas irrelevantes\n",
    "# En este dataset, la columna 'x', 'y', 'z'  se pueden considerar redundantes\n",
    "data.drop(columns=['x', 'y', 'z'], inplace=True)"
   ],
   "id": "c91a3352fba625b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_ANÁLISIS EXPLORATORIO DE DATOS (EDA)_*\n",
    "\n",
    "- EDA Univariante: Objetivo -> Entender la distribución de cada variable por separado.\n",
    "- EDA Bivariante: Objetivo -> Explorar la relación entre dos variables.\n",
    "- EDA Multivariante: Objetivo -> Entender la interacción entre más de dos variables.\n"
   ],
   "id": "473b307a9c5c3bc7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# EDA UNIVARIANTE:\n",
    "# Se realizan histograma de las columnas numéricas\n",
    "variables_numeric = ['carat', 'depth', 'table', 'price']\n",
    "\n",
    "for col in variables_numeric:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.set_style(\"white\")\n",
    "    sns.histplot(data[col], kde=True, bins=30, color=\"olivedrab\", edgecolor=\"black\")\n",
    "    plt.title(f'Distribución de {col}', fontsize=16, fontweight=\"bold\", color=\"y\")\n",
    "    plt.xlabel(col, fontsize=16, fontweight=\"bold\", color=\"darkseagreen\")\n",
    "    plt.ylabel('Frecuencia', fontsize=16, fontweight=\"bold\", color=\"darkseagreen\")\n",
    "    plt.show()"
   ],
   "id": "76df060fdc82ea96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Estadísticas descriptivas para variables numéricas\n",
    "data[variables_numeric].describe()"
   ],
   "id": "985e649f7527c35c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Análisis de variables categóricas\n",
    "# Se realizan histogramas de las variables categóricas\n",
    "variables_categoric = ['cut', 'color', 'clarity']\n",
    "\n",
    "for col in variables_categoric:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(x=data[col], order=data[col].value_counts().index, color=\"firebrick\", edgecolor=\"black\")\n",
    "    plt.title(f'Frecuencia de {col}', fontsize=16, fontweight=\"bold\", color=\"sienna\")\n",
    "    plt.xlabel(col, fontsize=16, fontweight=\"bold\", color=\"indianred\")\n",
    "    plt.ylabel('Frecuencia', fontsize=16, fontweight=\"bold\", color=\"indianred\")\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "3b9869ca4afc5c02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Frecuencia de las variables categóricas\n",
    "for col in variables_categoric:\n",
    "    print(f\"\\nDistribución de {col}:\")\n",
    "    print(data[col].value_counts())"
   ],
   "id": "e5d8e123ba8a964c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "En estas semanas también hemos visto la simetría o la asimetría de una distribución. Esta, medida con .skew(), forma parte del EDA univariante. Se utiliza principalmente para entender la distribución de las variables numéricas y evaluar si están sesgadas hacia la derecha (asimetría positiva) o hacia la izquierda (asimetría negativa).",
   "id": "78caa132c96f72d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Simetría de las variables numéricas\n",
    "data[variables_numeric].skew()\n"
   ],
   "id": "1865f8f796e535e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Las variables carat, table, y price presentan asimetría a la derecha (sesgo positivo), lo que significa que la mayoría de los datos están concentrados en el lado inferior de su rango. Algunos valores son más altos y arrastran la cola de la distribución hacia la derecha.\n",
    "En cambio, Depth tiene una ligera asimetría a la izquierda (sesgo negativo), lo que indica que la mayoría de los valores son relativamente altos, pero con algunos valores más bajos."
   ],
   "id": "79d8f50b9dadc470"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#EDA BIVARIANTE:\n",
    "# Diagrama de dispersión entre carat y price\n",
    "sns.set_style(\"white\")\n",
    "sns.scatterplot(data=data, x='carat', y='price', color=\"palevioletred\", edgecolor=\"black\")\n",
    "plt.title('Relación entre Carat y Price', fontsize=16, fontweight=\"bold\", color=\"violet\")\n",
    "plt.xlabel('Carat', fontsize=16, fontweight=\"bold\", color=\"rosybrown\")\n",
    "plt.ylabel('Price', fontsize=16, fontweight=\"bold\", color=\"rosybrown\")\n",
    "plt.show()"
   ],
   "id": "da2fd2d37a990ba0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Diagrama de dispersión entre depth y price\n",
    "sns.set_style(\"white\")\n",
    "sns.scatterplot(data=data, x='depth', y='price', color=\"goldenrod\", edgecolor=\"black\" )\n",
    "plt.title('Relación entre Depth y Price', fontsize=16, fontweight=\"bold\", color=\"tan\")\n",
    "plt.xlabel('Depth', fontsize=16, fontweight=\"bold\", color=\"moccasin\")\n",
    "plt.ylabel('Price', fontsize=16, fontweight=\"bold\", color=\"moccasin\")\n",
    "plt.show()"
   ],
   "id": "ae875a66a535b1ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "En el primer caso, vemos como Price y Carat tienen una relación muy alta, a mayor tamaño, mayor será el precio. Sin embargo, no podemos decir lo mismo en la otra comparación con la profundidad.",
   "id": "c530d4cefd33002e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Boxplot de price según cut\n",
    "sns.set_style(\"white\")\n",
    "sns.boxplot(data=data, x='cut', y='price', color=\"lightcoral\")\n",
    "plt.title('Distribución de Price por Cut',  fontsize=16, fontweight=\"bold\", color=\"red\")\n",
    "plt.xlabel('Cut', fontsize=16, fontweight=\"bold\", color=\"darkred\")\n",
    "plt.ylabel('Price', fontsize=16, fontweight=\"bold\", color=\"darkred\")\n",
    "plt.show()"
   ],
   "id": "96e16732972de4ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Boxplot de carat según cut\n",
    "sns.set_style(\"white\")\n",
    "sns.boxplot(data=data, x='cut', y='carat',color=\"lightcyan\")\n",
    "plt.title('Distribución de Carat por Cut',  fontsize=16, fontweight=\"bold\", color=\"turquoise\")\n",
    "plt.xlabel('Cut', fontsize=16, fontweight=\"bold\", color=\"skyblue\")\n",
    "plt.ylabel('Carat', fontsize=16, fontweight=\"bold\", color=\"skyblue\")\n",
    "plt.show()"
   ],
   "id": "f1f8ed981965bbc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Los boxplots muestran las diferencias en la mediana, los cuartiles y los valores atípicos entre las categorías de cut. Por ejemplo, se puede ver que el cut más alto tiende a tener diamantes de mayor precio y mayor tamaño.",
   "id": "f1ac8fc41da95987"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Crear una tabla de contingencia entre dos variables categóricas\n",
    "contingency_table = data.pivot_table(index=['cut', 'color'], columns='clarity', aggfunc='size', fill_value=0, observed=False)\n",
    "contingency_table\n"
   ],
   "id": "38eb05784aef787d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Una tabla de contingencia es una forma de visualizar cómo se distribuyen las categorías de dos o más variables categóricas. Te permite ver cuántas veces aparecen combinaciones específicas de categorías.",
   "id": "4a76b5a085698002"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gráfico de barras apiladas comparando 'cut' y 'color'\n",
    "sns.set_style('whitegrid')\n",
    "pd.crosstab(data['cut'], data['color']).plot(kind='bar', stacked=True, cmap='viridis')\n",
    "plt.title('Distribución de Cut y Color', fontsize=16, fontweight=\"bold\", color=\"mediumspringgreen\")\n",
    "plt.xlabel('Cut', fontsize=16, fontweight=\"bold\", color=\"teal\")\n",
    "plt.ylabel('Frecuencia', fontsize=16, fontweight=\"bold\", color=\"teal\")\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de barras apiladas comparando 'cut' y 'clarity'\n",
    "sns.set_style('whitegrid')\n",
    "pd.crosstab(data['cut'], data['clarity']).plot(kind='bar', stacked=True, cmap='flare')\n",
    "plt.title('Distribución de Cut y Clarity', fontsize=16, fontweight=\"bold\", color=\"plum\")\n",
    "plt.xlabel('Cut', fontsize=16, fontweight=\"bold\", color=\"palevioletred\")\n",
    "plt.ylabel('Frecuencia', fontsize=16, fontweight=\"bold\", color=\"palevioletred\")\n",
    "plt.show()\n"
   ],
   "id": "724109702cdfa66a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Un gráfico de barras apiladas es útil para ver la distribución de las categorías en relación con otras variables categóricas. Esto te permite comparar cómo se distribuyen las categorías dentro de otra categoría.",
   "id": "5ba825db844ec72c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Calculando la matriz de correlación entre las variables numéricas\n",
    "corr_matrix = data[['carat', 'depth', 'table', 'price']].corr()\n",
    "\n",
    "# Mapa de calor de la matriz de correlación\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_style(\"white\")\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='rocket', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Mapa de Calor de Correlación entre Variables Numéricas', fontsize=16, fontweight=\"bold\", color=\"red\")\n",
    "plt.show()\n"
   ],
   "id": "39d403cb63aa4867",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Se puede ver la relación de las variables categóricas utilizando la matriz de correlación transformándolas en variables numéricas mediante técnicas Label Encoding.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar variables categóricas en valores numéricos\n",
    "le = LabelEncoder()\n",
    "data_codify = data.copy()\n",
    "data_codify['cut'] = le.fit_transform(data['cut'])\n",
    "data_codify['color'] = le.fit_transform(data['color'])\n",
    "data_codify['clarity'] = le.fit_transform(data['clarity'])\n",
    "\n",
    "# Matriz de correlación\n",
    "corr_matrix_categor = data_codify[['cut', 'color', 'clarity']].corr()\n",
    "\n",
    "# Mapa de calor de la correlación\n",
    "sns.set_style('whitegrid')\n",
    "sns.heatmap(corr_matrix_categor, annot=True, cmap='viridis_r', fmt='.2f')\n",
    "plt.title('Mapa de Calor de Correlación entre Variables Categóricas', fontsize=16, fontweight=\"bold\", color=\"deepskyblue\")\n",
    "plt.show()\n"
   ],
   "id": "14acc65e1f1c2bce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#EDA MULTIVARIANTE:\n",
    "# Pairplot de las variables numéricas (carat, depth, table, price)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set_style(\"white\")\n",
    "sns.pairplot(data[['carat', 'depth', 'table', 'price']], diag_kind='kde')\n",
    "plt.suptitle('Gráfico de Pares: Relación entre variables', y=1.02, fontsize=16, fontweight=\"bold\", color=\"royalblue\")\n",
    "plt.show()\n"
   ],
   "id": "8632c41606ae1330",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Un gráfico de pares o pairplot muestra todas las combinaciones de pares de variables, lo que te permite ver patrones, correlaciones y posibles agrupamientos entre ellas.",
   "id": "644690b1e115afab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Crear un gráfico de violín para cada columna numérica en función de 'cut'\n",
    "col_numeric = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "for col in col_numeric:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.violinplot(data=data, hue='cut', y=col, palette='magma')\n",
    "    plt.title(f'Distribución de {col} por Cut', fontsize=16, fontweight=\"bold\", color=\"tomato\")\n",
    "    plt.legend(title='Cut', loc='center', bbox_to_anchor=(0.5, -0.05), ncol=2)\n",
    "    plt.show()"
   ],
   "id": "4b2252f9e4efa68b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Los gráficos de violín son útiles para comparar las distribuciones de una variable numérica en diferentes categorías. En nuestro caso, se puede comparar la distribución de variables como price, carat, etc., para cada categoría de cut. Los violines más anchos indican una mayor concentración de valores en esa área. Es útil para ver si las distribuciones de price o carat son similares o difieren dependiendo del cut.",
   "id": "dc73e82be2a63213"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como en las clases también hemos mencionado la libreria plotly express para realizar gráficos interactivos, voy a trabajar un poco con ella.",
   "id": "2c7b4932176ba129"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "#Gráfico de dispersión 3D para visualizar la relación entre tres variables numéricas: carat, depth y price. Además, usaremos el parámetro color para diferenciar los puntos según la variable categórica cut.\n",
    "\n",
    "fig = px.scatter_3d(data,\n",
    "                    x='carat',\n",
    "                    y='depth',\n",
    "                    z='price',\n",
    "                    color='cut',\n",
    "                    title=\"Gráfico 3D: Relación entre Carat, Depth y Price\",\n",
    "                    labels={\"carat\": \"Carat\", \"depth\": \"Depth\", \"price\": \"Price\"})\n",
    "\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "1b8627a7d15a2f33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.line(data, x=\"price\", y=\"carat\", color=\"cut\", line_group=\"cut\", title=\"Carat vs Price por Cut\")\n",
    "fig.show()\n"
   ],
   "id": "6b5beb10c4d5888b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Seleccionamos las variables numéricas\n",
    "df_num = data[['carat', 'depth', 'table', 'price']]\n",
    "\n",
    "# Estandarizamos las variables\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicamos PCA\n",
    "pca = PCA(n_components=2)  # Reduciendo a 2 componentes principales\n",
    "pca_components = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Creamos un DataFrame con los componentes principales\n",
    "pca_df = pd.DataFrame(pca_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Gráfica con los componentes principales\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.5, cmap='flare', c=data['price'])\n",
    "plt.title('PCA: Componentes Principales', fontsize=16, fontweight=\"bold\", color=\"red\")\n",
    "plt.xlabel('Componente Principal 1', fontsize=16, fontweight=\"bold\", color=\"tomato\")\n",
    "plt.ylabel('Componente Principal 2', fontsize=16, fontweight=\"bold\", color=\"tomato\")\n",
    "plt.colorbar(label='Price')\n",
    "plt.show()\n",
    "\n",
    "# Ver la varianza explicada por los componentes\n",
    "print(f\"Varianza explicada por PC1: {pca.explained_variance_ratio_[0]:.4f}\")\n",
    "print(f\"Varianza explicada por PC2: {pca.explained_variance_ratio_[1]:.4f}\")\n",
    "print(f\"Varianza total explicada: {sum(pca.explained_variance_ratio_):.4f}\")\n"
   ],
   "id": "ac369ec7170662d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "PCA es útil cuando se tienen muchas variables numéricas y se desea reducir la dimensionalidad mientras se mantiene la mayor parte de la variabilidad en los datos. Esto nos puede ayudar a visualizarlos de forma más clara y también identificar patrones o agrupamientos. En el gráfico de PCA, se puede ver cómo los datos se agrupan en función de los componentes principales.\n",
    "\n",
    "En este caso, vemos que los datos están agrupados en el centro, lo que puede sugerir una baja Varianza en los datos originales, los datos están muy correlacionados, o incluso la estandarización es insuficiente o incorrecta. Por este último motivo vamos a aplicar el método mencionado anteriormente, RobustScaler.\n"
   ],
   "id": "36b249c38cbb3b38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Estandarizamos las variables con RobustScaler\n",
    "scaler = RobustScaler()\n",
    "df_robust_scaled = scaler.fit_transform(df_num)\n",
    "\n",
    "# Aplicamos PCA\n",
    "pca = PCA(n_components=2)  # Reduciendo a 2 componentes principales\n",
    "pca_components = pca.fit_transform(df_robust_scaled)\n",
    "\n",
    "# Crear un DataFrame con los componentes principales\n",
    "pca_robust_df = pd.DataFrame(pca_components, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Graficar los componentes principales\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pca_robust_df['PC1'], pca_robust_df['PC2'], alpha=0.5, cmap='viridis', c=data['price'])\n",
    "plt.title('PCA con RobustScaler: Componentes Principales',fontsize=16, fontweight=\"bold\", color=\"c\")\n",
    "plt.xlabel('Componente Principal 1', fontsize=16, fontweight=\"bold\", color=\"dodgerblue\")\n",
    "plt.ylabel('Componente Principal 2', fontsize=16, fontweight=\"bold\", color=\"dodgerblue\")\n",
    "plt.colorbar(label='Price')\n",
    "plt.show()\n",
    "\n",
    "# Ver la varianza explicada por los componentes\n",
    "print(f\"Varianza explicada por PC1: {pca.explained_variance_ratio_[0]:.4f}\")\n",
    "print(f\"Varianza explicada por PC2: {pca.explained_variance_ratio_[1]:.4f}\")\n",
    "print(f\"Varianza total explicada: {sum(pca.explained_variance_ratio_):.4f}\")\n"
   ],
   "id": "f153f5f5d3695617",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Resultados:\n",
    "La varianza total explicada es muy similar en ambos casos, lo que significa que, en términos generales, ambas escalas logran capturar prácticamente la misma cantidad de información sobre los datos. StandardScaler parece explicar mejor la varianza en el primer componente principal (PC1), con un 49.35% frente al 41.96% de RobustScaler. Esto indica que, con StandardScaler, el primer componente principal captura más de la variabilidad de los datos. Sin embargo, RobustScaler parece distribuir la varianza de manera más equilibrada entre PC1 (41.96%) y PC2 (37.45%).\n",
    "\n",
    "Dado que nuestros datos tienen outliers o valores extremos, RobustScaler es una la mejor opción, ya que se basa en la mediana y el rango intercuartílico, haciéndola menos sensible a los outliers."
   ],
   "id": "52b20c0e95e079aa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_PREPARACIÓN DE DATOS PARA EL MODELADO_*\n",
    "\n",
    "Resumen del proceso de preparación de datos:\n",
    "\n",
    "+ Manejo de valores nulos → Imputación o eliminación.\n",
    "+ Codificación de variables categóricas → One-Hot o Label Encoding.\n",
    "+ Escalado de datos numéricos → Estandarización o normalización.\n",
    "+ Eliminación de variables irrelevantes\n",
    "+ División en conjuntos de entrenamiento y prueba.\n",
    "\n"
   ],
   "id": "8284f813c8ece37f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1fe7a959f429bc9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5b927a328d63fd9c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
