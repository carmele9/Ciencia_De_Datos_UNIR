{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Importamos las librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargamos el dataset 'tips' desde seaborn\n",
    "data = sns.load_dataset('tips')\n",
    "\n",
    "# Mostramos las primeras filas del dataset\n",
    "data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*_ANÁLISIS DE ESTADÍSTICAS DESCRIPTIVAS:_*",
   "id": "efc6c03381b2d4dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Informacion del dataset:\n",
    "# Se muestra los tipos de datos, cantidad de valores no nulos y tamaño del dataset\n",
    "data.info()"
   ],
   "id": "44797032582c28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Resumen estadístico de variables numéricas:\n",
    "# Nos proporciona estadísticas como media, desviación estándar, mínimo, máximo e información sobre los cuartiles.\n",
    "data.describe()"
   ],
   "id": "b8bb17c1863dddf1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Resumen de variables categóricas:\n",
    "# Se proporciona estadísticas sobre datos categóricos (valores únicos y frecuencia).\n",
    "data.describe(include=\"category\")"
   ],
   "id": "32cdf87283f223d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Verificación de valores nulos por columna:\n",
    "# Se detecta si hay datos faltantes en alguna columna.\n",
    "data.isnull().sum()"
   ],
   "id": "8e44790a68d4ce87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Valores únicos en columnas categóricas:\n",
    "# Se muestra los distintos valores que existen en cada columna categórica.\n",
    "for col in data.select_dtypes(include=[\"category\"]).columns:\n",
    "    print(data[col].unique())"
   ],
   "id": "4f25a18e2e89ea5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Distribución de la variable tip:\n",
    "# Para mejor entendimiento de la columna <tips>, se procede a ver su distribución.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.histplot(data[\"tip\"], kde=True, bins=20, color=\"darkgoldenrod\", edgecolor=\"black\")\n",
    "plt.title('Distribución de la columna tip', fontsize=16, fontweight=\"bold\", color=\"peru\")\n",
    "plt.xlabel('Tip', fontsize=14, fontweight=\"bold\")\n",
    "plt.ylabel('Frecuencia', fontsize=14, fontweight=\"bold\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ],
   "id": "64b52e16b85630d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Interacción entre variables\n",
    "# Se puede crear una nueva variable que puedan tener una relación conjunta con la columna <tip>.\n",
    "data['bill_per_person'] = round(data['total_bill'] / data['size'], 2)\n",
    "data.head()"
   ],
   "id": "5916b9396fc6d4a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Matriz de correlación:\n",
    "# Se analiza la relación entre las variables numéricas.\n",
    "# Se selecciona solo columnas numéricas\n",
    "columnas_num = data.select_dtypes(include=['float64', 'int64'])\n",
    "columnas_num.corr()"
   ],
   "id": "b07211b278537f0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Se hace una representación gráfica de esta misma matriz de correlación:\n",
    "matriz_corr = columnas_num.corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.set_style(\"white\")\n",
    "sns.heatmap(matriz_corr, annot=True, cmap=\"rocket\", fmt='.2f', linewidths=0.5,  linecolor='black')\n",
    "plt.title('Matriz de Correlación entre Variables Numéricas', fontsize=16, fontweight='bold', color=\"indianred\")\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ],
   "id": "de193e2675103b96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_LIMPIEZA DE DATOS:_*\n",
    "\n",
    "1. Revisar valores nulos.\n",
    "2. Detectar y tratar valores atípicos (outliers).\n",
    "3. Revisar y convertir tipos de datos si es necesario.\n",
    "4. Eliminar columnas irrelevantes."
   ],
   "id": "a4e77dd346d968b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Primero, verificamos si existen valores nulos en el dataset. Este paso se realizó anteriormente y el resultado fue negativo. Al no tener valores nulos, se sigue con la limpieza.",
   "id": "661442b2447ea4eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Detectar y tratar valores atípicos (outliers):\n",
    "# Se puede detectar valores atípicos en las columnas numéricas utilizando diagramas de caja.\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.set_style(\"white\")\n",
    "sns.boxplot(data=data[['total_bill', 'tip', 'size']], palette=\"magma\")\n",
    "plt.title(\"Detección de valores atípicos\", fontsize=16, fontweight='bold', color=\"indianred\")\n",
    "plt.show()"
   ],
   "id": "1ac8142bbe58947d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como hemos detectado valores atípicos extremos, podemos eliminarlos, considerando que son errores. Para eliminar outliers, podemos usar el rango intercuartílico (IQR) para filtrar datos del rango.",
   "id": "538ac4e2ade93900"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Se reconocen cuáles son el primer y tercer cuartil, para calcular el IQR\n",
    "Q1 = data[['total_bill', 'tip', 'size']].quantile(0.25)\n",
    "Q3 = data[['total_bill', 'tip', 'size']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Se define los límites y se filtra los datos dentro del rango\n",
    "data_limpio = data[~((data[['total_bill', 'tip', 'size']] < (Q1 - 1.5 * IQR)) |\n",
    "                      (data[['total_bill', 'tip', 'size']] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(f\"Datos antes de limpiar outliers: {data.shape[0]} filas\")\n",
    "print(f\"Datos después de limpiar outliers: {data_limpio.shape[0]} filas\")"
   ],
   "id": "da7e653e0cd5db2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Revisar y convertir tipos de datos:\n",
    "data_limpio.dtypes"
   ],
   "id": "d60af616db2ca7bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dado que las columnas ['sex', 'smoker', 'day', 'time'] se encuentran como category, no hace falta convertir ni modificar ningún tipo de variable.",
   "id": "1a6f312228654dbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Eliminar columnas irrelevantes, si hace falta\n",
    "data_limpio.nunique()"
   ],
   "id": "e27dad8e50da9c1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Análisis de las columnas:\n",
    "\n",
    "- total_bill y tip: Variables numéricas importantes para el modelo.\n",
    "- sex, smoker, day, time, size: Tienen pocos valores únicos, lo que indica que son variables categóricas útiles para la predicción.\n",
    "\n",
    "En este caso, no parece haber columnas irrelevantes, ya que todas contienen información potencialmente útil para el modelo."
   ],
   "id": "24ad2491a5a0da7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_ANÁLISIS EXPLORATORIO DE DATOS (EDA)_*\n",
    "\n",
    "- EDA univariante: Para entender la distribución de cada variable.\n",
    "- EDA bivariante: Para analizar la relación entre dos variables.\n",
    "- EDA multivariante: Para explorar la relación entre múltiples variables simultáneamente.\n",
    "\n",
    "Este paso sirve para comprender la distribución de los datos y así saber si las variables siguen una distribución normal o están sesgadas. También nos ayuda a identificar patrones y relaciones y detectar problemas."
   ],
   "id": "69bde127e2fc7c3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#EDA Univariante (Análisis de una variable a la vez)\n",
    "# Variables numéricas\n",
    "col_numeric = ['total_bill', 'tip', 'size', 'bill_per_person']\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, col in enumerate(col_numeric, 1):\n",
    "    sns.set_style(\"white\")\n",
    "    plt.subplot(1, 4, i)\n",
    "    sns.histplot(data_limpio[col], kde=True, color=\"palevioletred\", edgecolor=\"black\")\n",
    "    plt.title(f'Distribución de {col}', fontsize=16, fontweight=\"bold\", color=\"violet\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3e5b6d149d98091c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Con esto podemos entender mejor las variables numéricas. Por ejemplo, vemos que la cuenta, total_bill, suele estar en valores de 10-20 dólares. También vemos que la propina, tip, suele estar en valores de 2 o 3 dólares aproximadamente. Finalmente, se entiende que el size, número de personas en la mesa del restaurante, suele rondar a dos personas.",
   "id": "1038706c38dfdf6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Variables categóricas\n",
    "col_categoric = ['sex', 'smoker', 'day', 'time']\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(col_categoric, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.set_style(\"white\")\n",
    "    sns.countplot(data=data_limpio, x=col,hue=col, palette=\"dark:salmon_r\", edgecolor=\"black\", legend=False)\n",
    "    plt.title(f'Conteo de {col}', fontsize=16, fontweight=\"bold\", color=\"crimson\")\n",
    "    plt.xlabel(col.capitalize(), fontsize=16, fontweight=\"bold\")\n",
    "    plt.ylabel('Frecuencia', fontsize=16, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6b7e1317bd2cdcf3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Estos resultados nos muestra que los clientes más frecuentes suelen ser hombres. Además, este restaurante suele ser frecuentado por clientes no fumadores en los días de sábado y domingo y en horario de cena.",
   "id": "e137cb39ed45fb18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#EDA Bivariante (Relación entre dos variables)\n",
    "# Se realiza un análisis gráfico para examinar las relaciones entre las variables numéricas (total_bill, tip, size) y una de las variables categóricas de tu conjunto de datos.\n",
    "\n",
    "for i, col in enumerate(col_categoric, 1):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style(\"white\")\n",
    "    g = sns.pairplot(data_limpio[['total_bill', 'tip', 'size', 'bill_per_person', col]], diag_kind='kde', palette='magma', hue=col)\n",
    "    g.fig.suptitle(f'Relaciones entre variables numéricas según {col}', fontsize=16, fontweight=\"bold\", color=\"mediumvioletred\", y=1.02)\n",
    "    plt.show()\n"
   ],
   "id": "694a430a0b2c5ce8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Relación entre variables categóricas y la columna <tip> como se nos pide en la actividad (boxplots)\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(col_categoric, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(x=data_limpio[col], y=data_limpio['tip'], palette=\"flare\", hue=data_limpio[col])\n",
    "    plt.title(f'Propina según {col}', fontsize=16, fontweight=\"bold\", color=\"rebeccapurple\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "f756afab1045cc4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#EDA Multivariante (Relación entre múltiples variables)\n",
    "# Se visualiza la relación entre varias variables simultáneamente.\n",
    "# Matriz de correlación para variables numéricas, a diferencia de la anterior matriz, esta se realizará con los datos limpiados, por ende se observa una diferencia en los resultados\n",
    "\n",
    "nueva_corr_matrx = data_limpio[['total_bill', 'tip', 'size', 'bill_per_person']].corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.set_style(\"white\")\n",
    "sns.heatmap(nueva_corr_matrx, annot=True, cmap='YlOrBr', fmt='.2f', linewidths=0.5, linecolor='black')\n",
    "plt.title('Matriz de Correlación entre Variables Numéricas', fontsize=16, fontweight='bold', color=\"salmon\")\n",
    "plt.xticks(fontsize=12, rotation=45)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ],
   "id": "be2fba5759828ea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Gráficos 3D (para variables numéricas)\n",
    "# Aquí estamos visualizando las relaciones entre 'total_bill', 'tip', y 'size' en tres dimensiones\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.set_style(\"white\")\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(data_limpio['total_bill'], data_limpio['tip'], data_limpio['size'], c=data_limpio['size'], cmap='Spectral')\n",
    "ax.set_xlabel('Total Bill', fontsize=10, fontweight='bold', color=\"slategrey\")\n",
    "ax.set_ylabel('Tip', fontsize=10, fontweight='bold', color=\"slategrey\")\n",
    "ax.set_zlabel('Size', fontsize=10, fontweight='bold', color=\"slategrey\")\n",
    "plt.show()"
   ],
   "id": "15046a9752a25141",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Análisis de Componentes Principales (PCA)\n",
    "# El PCA es útil para reducir la dimensionalidad de los datos, especialmente cuando se tiene muchas variables. Permite proyectar los datos en un espacio de menor dimensión para observar la variabilidad en los datos.\n",
    "# En este caso, se reduce las 3 variables originales a 2 componentes principales, lo que facilita la visualización y el análisis. También ayuda a ver cómo las tres variables interactúan y se agrupan, lo cual es difícil de hacer con más de dos variables.\n",
    "# Se utiliza el color de los puntos para representar la variable size, lo que añade una dimensión extra de análisis\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Se normaliza Normalizar los datos antes de aplicar PCA\n",
    "scaler = StandardScaler()\n",
    "data_norm = scaler.fit_transform(data_limpio[['total_bill', 'tip', 'size']])\n",
    "\n",
    "# Aplicando PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(data_norm)\n",
    "\n",
    "# Visualizando los dos primeros componentes principales\n",
    "plt.scatter(pca_components[:, 0], pca_components[:, 1], c=data_limpio['size'], cmap='magma')\n",
    "plt.title('PCA: Primeros dos componentes principales', fontsize=10, fontweight='bold', color=\"slategrey\")\n",
    "plt.xlabel('Componente Principal 1', fontsize=10, fontweight='bold', color=\"slategrey\")\n",
    "plt.ylabel('Componente Principal 2', fontsize=10, fontweight='bold', color=\"slategrey\")\n",
    "plt.colorbar(label='Tamaño')\n",
    "plt.show()"
   ],
   "id": "3a228b7749200435",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Al ver este gráfico, se puede ver que estas tres variables tienen relaciones lineales fuertes entre sí, y eso puede estar causando la alineación de los puntos en líneas.\n",
    "\n",
    "En otras palabras, la relación entre total_bill, tip y size es aproximadamente lineal, por ende, los primeros componentes principales del PCA capturan esas relaciones lineales. En este caso, el PCA ha creado un espacio de componentes donde los datos se distribuyen a lo largo de tres líneas casi paralelas, lo que indica que las variables son altamente correlacionadas y que el PCA ha encontrado la estructura lineal subyacente.\n",
    "\n",
    "Por ejemplo, la propina (tip) generalmente es una fracción del total de la factura (total_bill), y el tamaño (size) de la mesa puede afectar tanto al total de la factura como a la propina. Estas tres variables están relacionadas de manera proporcional (mesas más grandes tienden a tener una factura más alta y, por ende, una propina más alta), el PCA ha proyectado esos datos en una estructura lineal."
   ],
   "id": "f03ca5b858366d68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_PREPARACIÓN DE DATOS PARA EL MODELADO_*\n",
    "\n",
    "Resumen del proceso de preparación de datos:\n",
    "\n",
    "+ Manejo de valores nulos → Imputación o eliminación.\n",
    "+ Codificación de variables categóricas → One-Hot o Label Encoding.\n",
    "+ Escalado de datos numéricos → Estandarización o normalización.\n",
    "+ Eliminación de variables irrelevantes\n",
    "+ División en conjuntos de entrenamiento y prueba.\n"
   ],
   "id": "a3a6f2f3fa1325cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Manejo de valores faltantes\n",
    "# Como comprobamos anteriormente, este dataset no tiene valores nulos. Por consecuente, no hace falta hacer nada en este paso.\n",
    "data_limpio.isna().sum()"
   ],
   "id": "abb50d524cb01489",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Codificación de variables categóricas:\n",
    "# Para el modelo que se planteara después, se ha escogido trabajar con One-Hot Encoding.\n",
    "# Este sirve para transformar las categorías en columnas binarias (0 o 1). Es útil para variables categóricas como sex, smoker, day, time. No introduce relaciones espurias entre categorías aunque puede aumentar dimensionalidad si hay muchas categorías.\n",
    "\n",
    "data_encoded = pd.get_dummies(data_limpio, columns=['sex', 'smoker', 'day', 'time'], drop_first=True)\n",
    "data_encoded.head()"
   ],
   "id": "c9d2de81e512a69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Conversión a 0 y 1:\n",
    "# Para que los valores se muestren como 0 y 1 en lugar de False y True:\n",
    "\n",
    "data_encoded = data_encoded.astype(int)\n",
    "data_encoded.head()"
   ],
   "id": "1bfef5034a946ae0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Escalado de datos numéricos:\n",
    "# Teniendo en cuenta que vamos a realizar un modelo de regresión, se usará Estandarización (StandardScaler).\n",
    "# Este convierte los datos para que tengan media = 0 y desviación estándar = 1. Es el más indicado cuando los datos tienen una distribución normal o desconocida. También sirve cuando las variables tienen diferentes escalas (como total_bill y size).\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_encoded[['total_bill', 'tip', 'size']] = scaler.fit_transform(data_encoded[['total_bill', 'tip', 'size']])\n",
    "data_encoded.head()"
   ],
   "id": "690c0198fb7fcf18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "El siguiente paso consiste en la eliminación de variables irrelevantes. Anteriormente, he estudiado esto en la limpieza de datos, y llegué a la conclusión que todas las columnas aportan información relevante.",
   "id": "694ef69dead22674"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#División en conjuntos de entrenamiento y prueba\n",
    "# Para dividir los datos, se usará la función train_test_split, que permite separar el dataset en dos partes:\n",
    "# 1. Conjunto de entrenamiento (train set): Se utiliza para entrenar el modelo. Suele representar el 70-80% del total de los datos.\n",
    "# 2. Conjunto de prueba (test set): Se utiliza para evaluar el rendimiento del modelo. Suele representar el 20-30% del total de los datos.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Se define la columna <tip> como y las variables para predecir como X\n",
    "X = data_encoded.drop(columns=['tip'])  # Todas menos la columna <tip>\n",
    "y = data_encoded['tip']  # Solo la columna <tip>\n",
    "\n",
    "# División del dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Se muestra la forma de los conjuntos para verificar\n",
    "print(\"Shape de X_train:\", X_train.shape)\n",
    "print(\"Shape de X_test:\", X_test.shape)\n",
    "print(\"Shape de y_train:\", y_train.shape)\n",
    "print(\"Shape de y_test:\", y_test.shape)\n",
    "\n"
   ],
   "id": "530c96c0eb5ca6c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "*_MODELADO_*\n",
    "\n",
    "En mi caso, he decidido usar tanto la regresión lineal simple, aplicando la optimización Ridge y arboles usando regresión. Al final se comparará el rendimiento de todos y se tomará una decision sobre cuál será mejor emplear.\n",
    "\n",
    "Pasos para el modelado de regresión\n",
    "\n",
    "- Importar librerías necesarias.\n",
    "- Optimización de hiperparámetros\n",
    "- Crear y entrenar el modelo de regresión lineal.\n",
    "- Realizar predicciones con el conjunto de prueba.\n",
    "- Evaluar el modelo usando métricas adecuadas.\n"
   ],
   "id": "552d6f5250d9a37d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#La optimización de hiperparámetros busca optimizar estos para encontrar la mejor configuración para el modelo antes de entrenarlo completamente con los datos de entrenamiento.\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Se define el modelo y se especifica los hiperparámetros clave.\n",
    "ridge = Ridge()\n",
    "param_grid = {'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "# Se configura la búsqueda de hiperparámetros usando la técnica de GridSearchCV.\n",
    "# GridSearchCV divide automáticamente los datos de entrenamiento en subconjuntos (validación cruzada) para evaluar cada combinación de hiperparámetros. Además, selecciona la mejor combinación de tal manera que maximize el desempeño de este.\n",
    "grid_search = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train) # Se entrena el modelo\n",
    "\n",
    "# Se estudia cuál es el mejor modelo Ridge con hiperparámetros óptimos\n",
    "best_ridge = grid_search.best_estimator_\n"
   ],
   "id": "203908c9226ca875",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Interpretación de los resultados:\n",
    "\n",
    "- MAE: Indica el promedio de error en unidades monetarias (por ejemplo, dólares).\n",
    "- MSE/RMSE: Cuanto más bajos, mejor será la predicción del modelo.\n",
    "- R^2:\n",
    "   - Si R^2 ≈ 1, el modelo se ajusta bien a los datos.\n",
    "   - Si R^2 ≈ 0, el modelo no explica la variabilidad de los datos.\n",
    "   - Si R^2 es negativo, el modelo es peor que una predicción basada en la media."
   ],
   "id": "d23bb7a9a05a1d24"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluamos Ridge Regression en test\n",
    "y_pred_ridge = best_ridge.predict(X_test)\n",
    "\n",
    "print(\"Resultados Ridge Regression:\")\n",
    "print(\"Mejor alpha:\", grid_search.best_params_['alpha'])\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_ridge))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_ridge))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n",
    "print(\"R²:\", r2_score(y_test, y_pred_ridge))"
   ],
   "id": "c5d2e3a1df2d3235",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Se crea el modelo de regresión lineal\n",
    "model = LinearRegression()\n",
    "\n",
    "# Se entrena el modelo con los datos de entrenamiento creados anteriormente\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Se realiza las predicciones en con los datos de validación creados anteriormente\n",
    "y_pred_model = model.predict(X_test)"
   ],
   "id": "afb545cc73a4d15c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " #Se evalua el rendimiento del modelo\n",
    "mae = mean_absolute_error(y_test, y_pred_model)\n",
    "mse = mean_squared_error(y_test, y_pred_model)\n",
    "rmse = mean_squared_error(y_test, y_pred_model)\n",
    "r2 = r2_score(y_test, y_pred_model)\n",
    "\n",
    "# Se muestra los errores del modelo entrenado y testeado\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R^2: {r2:.2f}\")"
   ],
   "id": "cd53cef9dcf0efd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Se crea el modelo de árbol de decisión\n",
    "tree = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "\n",
    "# Se entrena el modelo con los datos de entrenamiento\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Se realiza las predicciones con los datos de validación\n",
    "y_pred_tree = tree.predict(X_test)\n"
   ],
   "id": "6fa9ac0247316b16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Se evalua el rendimiento del modelo\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "rmse_tree = np.sqrt(mse)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(\"Resultados Árbol de Regresión:\")\n",
    "print(f\"MAE: {mae_tree:.4f}\")\n",
    "print(f\"MSE: {mse_tree:.4f}\")\n",
    "print(f\"RMSE: {rmse_tree:.4f}\")\n",
    "print(f\"R²: {r2_tree:.4f}\")"
   ],
   "id": "b4520b1ae17774d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Validación cruzada (Cross-Validation)\n",
    "# Se puede ver si el modelo está sobreajustado, realizando una validación cruzada:\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores_ridge = cross_val_score(ridge, X, y, cv=5, scoring='r2')\n",
    "print(\"R^2 promedio en validación cruzada usando Ridge:\", scores_ridge.mean())\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "print(\"R^2 promedio en validación cruzada sin usar Ridge:\", scores.mean())\n",
    "\n",
    "scores_tree = cross_val_score(tree, X, y, cv=5, scoring='r2')\n",
    "print(\"R^2 promedio en validación cruzada usando arboles:\", scores.mean())\n"
   ],
   "id": "bf53543e19a8905e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Interpretación de resultados\n",
    "# Coeficientes de la regresión: Muestra qué variables tienen mayor influencia.\n",
    "\n",
    "print(\"Coeficientes:\", model.coef_)\n",
    "print(\"Intercepto:\", model.intercept_)\n",
    "\n"
   ],
   "id": "73c6892175c85c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Visualización de los resultados usando Ridge: Se compara los valores reales vs. predichos en un gráfico.\n",
    "sns.set_style(\"white\")\n",
    "sns.scatterplot(x=y_test, y=y_pred_ridge, alpha=0.5, color=\"chocolate\")\n",
    "plt.xlabel(\"Valores Reales\", fontsize=16, fontweight=\"bold\", color=\"darkred\")\n",
    "plt.ylabel(\"Valores Predichos\", fontsize=16, fontweight=\"bold\", color=\"darkred\")\n",
    "plt.title(\"Valores Reales vs. Predichos\", fontsize=16, fontweight=\"bold\", color=\"darkred\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.show()\n"
   ],
   "id": "e9a5e8d05d5027a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualización de los resultados sin usar Ridge: Se compara los valores reales vs. predichos en un gráfico.\n",
    "sns.set_style(\"white\")\n",
    "sns.scatterplot(x=y_test, y=y_pred_model, alpha=0.5, color=\"darkorchid\")\n",
    "plt.xlabel(\"Valores Reales\", fontsize=16, fontweight=\"bold\", color=\"rebeccapurple\")\n",
    "plt.ylabel(\"Valores Predichos\", fontsize=16, fontweight=\"bold\", color=\"rebeccapurple\")\n",
    "plt.title(\"Valores Reales vs. Predichos\", fontsize=16, fontweight=\"bold\", color=\"rebeccapurple\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.show()"
   ],
   "id": "a44053852850458",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualización de resultados usando los árboles de decision con regresión: Se compara los valores reales vs. predichos en un gráfico.\n",
    "sns.set_style(\"white\")\n",
    "sns.scatterplot(x=y_test, y=y_pred_tree, alpha=0.7, color=\"goldenrod\")\n",
    "plt.xlabel(\"Valores Reales\", fontsize=16, fontweight=\"bold\", color=\"orangered\")\n",
    "plt.ylabel(\"Valores Predichos\", fontsize=16, fontweight=\"bold\", color=\"orangered\")\n",
    "plt.title(\"Árbol de Decisión: Valores Reales vs Predichos\", fontsize=16, fontweight=\"bold\", color=\"orangered\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.show()"
   ],
   "id": "6c85c3a69e972d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Resultados del Modelo sin Ridge:\n",
    "- MAE (Error Absoluto Medio): 0.59, lo que indica cuán lejos están de las predicciones de los valores reales.\n",
    "- MSE (Error Cuadrático Medio): 0.55. El MSE es más bajo que el MAE, lo que sugiere que los errores más grandes afectan más el rendimiento del modelo.\n",
    "- RMSE (Raíz del Error Cuadrático Medio): 0.55, lo que refleja una dispersión moderada en las predicciones.\n",
    "- R^2 (Coeficiente de Determinación): 0.39. Indica que el 39% de la variabilidad de la variable (tip) se puede explicar mediante las variables predictoras. Aunque es una buena base, se puede mejorar el modelo.\n",
    "- R^2 Promedio en Validación Cruzada: 0.138. Un valor bajo sugiere: 1. el modelo puede estar sobreajustado, 2. los datos no son suficientemente representativos de todos los posibles patrones.\n",
    "\n",
    "Resultados del Modelo con Ridge:\n",
    "- MAE (Error Absoluto Medio): 0.60. Aumenta ligeramente en el modelo con Ridge, lo que indica que este podría estar penalizando más los coeficientes grandes.\n",
    "- MSE (Error Cuadrático Medio): 0.58. También es un poco más alto, lo que refuerza la idea de que este afecta el rendimiento.\n",
    "- RMSE (Raíz del Error Cuadrático Medio): 0.76. Es más alto que en el modelo sin Ridge. Esto significa que, ciertamente, el Ridge ayuda a reducir el sobreajuste, pero suprime demasiado los coeficientes, afectando la precisión de las predicciones.\n",
    "- R^2 (Coeficiente de Determinación): 0.36, es algo inferior al modelo sin Ridge, lo que indica que se ha reducido ligeramente la capacidad del modelo para ajustar los datos.\n",
    "- R^2 Promedio en Validación Cruzada: 0.15, ligeramente mejor que el modelo sin Ridge, otro indicativo que explica como ha ayudado a reducir el sobreajuste.\n",
    "\n",
    "Resultados del Modelo con Árboles de Decisión:\n",
    "- MAE (Error Absoluto Medio): 0.6081, un poco mayor que la regresión lineal (0.5900) y Ridge (0.5962), el error del árbol es ligeramente mayor que el de los modelos lineales.\n",
    "- MSE (Error Cuadrático Medio): 0.5747, es un poco mayor que la regresión lineal (0.5500) pero menor que Ridge (0.5836). Muestra que el modelo del árbol tiene un error mayor, pero sigue siendo razonable.\n",
    "- RMSE (Raíz del Error Cuadrático Medio): Similar al MSE, el árbol tiene un RMSE de 0.7581, mayor que los modelos lineales (0.7420), lo que sugiere un ligero empeoramiento en la precisión.\n",
    "- R² (Coeficiente de Determinación): 0.3699, menor que la regresión lineal (0.3900), lo que indica que explica un poco menos la variabilidad de los datos en comparación con los modelos lineales.\n",
    "- R^2 Promedio en Validación Cruzada: 0.138, el mismo valor que el modelo de regresión sin Ridge.\n",
    "\n",
    "Coeficientes de la Regresión Sin Ridge:\n",
    "- Los coeficientes obtenidos son más grandes en comparación con el otro, lo que indica que el modelo sin Ridge está \"ajustando más\" los datos, pero puede haber un sobreajuste. Por ejemplo: Coeficiente de sex_Female = -0.179: A medida que una persona es más propensa a ser mujer, la propina disminuye en ese valor.\n",
    "\n",
    "CONCLUSION:\n",
    "Valorando la capacidad de generalización y no priorizando un modelo que no se ajuste demasiado a los datos de entrenamiento, Ridge Regression es la mejor opción.\n",
    "Sin embargo, si se prefiere un modelo que explote todo el poder predictivo de las características, es mejor optar por el modelo sin Ridge.\n",
    "Finalmente, El modelo de árbol de decisión no supera a la regresión lineal en términos de precisión. Tiene un rendimiento ligeramente inferior y el error es un poco mayor, lo que sugiere que el modelo de regresión lineal es más adecuado para estos datos.\n"
   ],
   "id": "fe5f50ef6d7a15a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "64489f9ab0f39373",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
